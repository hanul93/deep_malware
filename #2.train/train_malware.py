# -*- coding: utf-8 -*-

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import math
import random
import sys
import os


# export TF_CPP_MIN_LOG_LEVEL=3

def sigmoid(x):
    return 1 / (1 + math.exp(-x))


def xavier_init(n_inputs, n_outputs, uniform=True):
    if uniform:
        # 6 was used in the paper.
        init_range = math.sqrt(6.0 / (n_inputs + n_outputs))
        return tf.random_uniform_initializer(-init_range, init_range)
    else:
        # 3 gives us approximately the same limits as above since this repicks
        # values greater than 2 standard deviations from the mean.
        stddev = math.sqrt(3.0 / (n_inputs + n_outputs))
        return tf.truncated_normal_initializer(stddev=stddev)


def load_bin(fname, y):
    ret_x = []
    ret_y = []

    buf = open(fname, 'rb').read()
    for i in range(len(buf) / 1024):
        data = map(float, map(ord, buf[i*1024:(i+1)*1024]))
        ret_x.append(data)
    
        if y == 0:
            ret_y.append([1.0, 0.0])
        elif y == 1:
            ret_y.append([0.0, 1.0])

    return ret_x, ret_y


def ready_set():
    x, y = load_bin('train_set.bin', 1)
    t_x, t_y = load_bin('normal_set.bin', 0)
    x += t_x
    y += t_y

    np_x = np.array(x)
    np_y = np.array(y)

    return np_x, np_y


learning_rate = 0.001
training_epochs = 20
batch_size = 100
display_step = 1

tx, ty = load_bin('train_set.bin', 1)
nx, ny = load_bin('normal_set.bin', 0)

test_tx, test_ty = load_bin('test_malware_set.bin', 1)
test_nx, test_ny = load_bin('test_normal_set.bin', 0)

X = tf.placeholder(tf.float32, [None, 1024])
Y = tf.placeholder(tf.float32, [None, 2])


W1 = tf.get_variable('W1', shape=[1024, 1024], initializer=xavier_init(1024, 1024, False))
W2 = tf.get_variable('W2', shape=[1024, 1024], initializer=xavier_init(1024, 1024, False))
W3 = tf.get_variable('W3', shape=[1024, 1024], initializer=xavier_init(1024, 1024, False))
W4 = tf.get_variable('W4', shape=[1024, 2], initializer=xavier_init(1024, 2, False))

'''
W1 = tf.Variable(tf.zeros([1024, 1024]), )
W2 = tf.Variable(tf.zeros([1024, 1024]))
W3 = tf.Variable(tf.zeros([1024, 1024]))
W4 = tf.Variable(tf.zeros([1024, 2]))
'''

B1 = tf.Variable(tf.zeros([1024]))
B2 = tf.Variable(tf.zeros([1024]))
B3 = tf.Variable(tf.zeros([1024]))
B4 = tf.Variable(tf.zeros([2]))

# L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))
# L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), B2))
# L3 = tf.nn.relu(tf.add(tf.matmul(L2, W3), B3))

dropout_rate = tf.placeholder('float')
_L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))
L1 = tf.nn.dropout(_L1, dropout_rate)
_L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), B2))
L2 = tf.nn.dropout(_L2, dropout_rate)
_L3 = tf.nn.relu(tf.add(tf.matmul(L2, W3), B3))
L3 = tf.nn.dropout(_L3, dropout_rate)

hypothesis = tf.add(tf.matmul(L3, W4), B4)

# cross-entropy 모델을 설정한다.
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

# 테스트 데이터 준비
test_x = np.array(test_tx + test_nx)
test_y = np.array(test_ty + test_ny)


# 그래프를 준비한다.
g_x = []
g_y = []

# 모델을 학습한다.
do_train = 1

init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)

    if do_train == 1:
        acc_val = 0.0
        epoch = 0

        old_acc_val = 0.
        acc_val_count = 0

        try:
            while True:  # acc_val < 0.99 or epoch < 20:  # 99% 진단율까지 올리기
                if old_acc_val == acc_val:
                    acc_val_count += 1
                else:
                    acc_val_count = 0
                    old_acc_val = acc_val

                if acc_val > 0.99 and epoch > 20 and acc_val_count == 5:
                    break

                avg_cost = 0.
                total_batch = int(len(tx+nx) / batch_size) + 1 if int(len(tx+nx) % batch_size) else 0

                for i in range(total_batch):
                    # 순차 선택
                    np_x = np.array(tx + nx)
                    np_y = np.array(ty + ny)

                    if i != total_batch - 1:
                        batch_xs, batch_ys = np_x[i * 100:(i + 1) * 100], np_y[i * 100:(i + 1) * 100]
                    else:  # 마지막이면 잔여 개수가 100개가 아니라도 끝까지 테스팅
                        batch_xs, batch_ys = np_x[i * 100:], np_y[i * 100:]
                    sess.run(optimizer, feed_dict={X:batch_xs, Y:batch_ys, dropout_rate:0.8})
                    avg_cost += sess.run(cost, feed_dict={X:batch_xs, Y:batch_ys, dropout_rate:0.8}) / total_batch

                # 학습된 모델이 얼마나 정확한지를 출력한다.
                correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))
                accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))
                acc_val = accuracy.eval({X: np.array(test_x), Y: np.array(test_y), dropout_rate: 1.0})

                if epoch % display_step == 0:
                    print 'Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost), 'Acc:', '{:.9f}'.format(acc_val)
                    g_x.append(epoch+1)
                    g_y.append(acc_val)

                epoch += 1
        except KeyboardInterrupt:
            pass

        print 'END'

        print 'Acc:', acc_val

        saver = tf.train.Saver()
        save_path = saver.save(sess, './data/k2.pd')
        print save_path

        plt.figure(1)
        plt.plot(g_x, g_y)
        plt.show()
    else:
        epoch = training_epochs-1
        saver = tf.train.Saver()
        saver.restore(sess, './k2.pd')

        test_x, test_y = load_bin('1.bin', 1)
        # test_x, test_y = load_bin('normal_set.bin', 0)
        
        t_x = np.array(test_x)[2]

        X = tf.placeholder(tf.float32, [1, 1024])

        _L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))
        L1 = tf.nn.dropout(_L1, dropout_rate)
        _L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), B2))
        L2 = tf.nn.dropout(_L2, dropout_rate)
        _L3 = tf.nn.relu(tf.add(tf.matmul(L2, W3), B3))
        L3 = tf.nn.dropout(_L3, dropout_rate)

        hypothesis = tf.add(tf.matmul(L3, W4), B4)

        r = sess.run(hypothesis, feed_dict={X: np.array([t_x]), dropout_rate:1.0})
        
        print sigmoid(r[0][0]), sigmoid(r[0][1])




        

